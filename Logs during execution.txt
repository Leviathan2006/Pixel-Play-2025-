Time
#
Log Message
11.7s	1	Collecting pytorch-pretrained-biggan
11.7s	2	  Downloading pytorch_pretrained_biggan-0.1.1-py3-none-any.whl.metadata (11 kB)
11.7s	3	Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-biggan) (2.4.1+cu121)
11.7s	4	Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-biggan) (1.26.4)
11.7s	5	Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-biggan) (1.35.83)
11.7s	6	Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-biggan) (2.32.3)
11.7s	7	Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-biggan) (4.66.5)
11.7s	8	Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (3.16.1)
11.7s	9	Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (4.12.2)
11.7s	10	Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (1.13.3)
11.7s	11	Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (3.3)
11.7s	12	Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (3.1.4)
11.7s	13	Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (2024.6.1)
11.7s	14	Requirement already satisfied: botocore<1.36.0,>=1.35.83 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-biggan) (1.35.83)
11.7s	15	Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-biggan) (1.0.1)
11.7s	16	Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-biggan) (0.10.4)
11.7s	17	Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-biggan) (3.3.2)
11.7s	18	Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-biggan) (3.10)
11.7s	19	Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-biggan) (2.2.3)
11.8s	20	Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-biggan) (2024.8.30)
11.8s	21	Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.83->boto3->pytorch-pretrained-biggan) (2.8.2)
11.8s	22	Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-biggan) (2.1.5)
11.8s	23	Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch-pretrained-biggan) (1.3.0)
11.8s	24	Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.83->boto3->pytorch-pretrained-biggan) (1.16.0)
11.8s	25	Downloading pytorch_pretrained_biggan-0.1.1-py3-none-any.whl (27 kB)
14.2s	26	Installing collected packages: pytorch-pretrained-biggan
14.4s	27	Successfully installed pytorch-pretrained-biggan-0.1.1
17.8s	28	WordNet loaded successfully. Example synsets: [Synset('example.n.01'), Synset('model.n.07'), Synset('exemplar.n.01'), Synset('example.n.04'), Synset('case.n.01'), Synset('exercise.n.04')]
17.8s	29	[Synset('horse.n.01'), Synset('horse.n.02'), Synset('cavalry.n.01'), Synset('sawhorse.n.01'), Synset('knight.n.02'), Synset('horse.v.01')]
25.0s	30	
  0%|          | 0/210849368 [00:00<?, ?B/s]
  0%|          | 330752/210849368 [00:00<01:04, 3286336.65B/s]
  2%|▏         | 4457472/210849368 [00:00<00:08, 25568285.25B/s]
  6%|▌         | 12499968/210849368 [00:00<00:03, 50579967.42B/s]
 10%|▉         | 20335616/210849368 [00:00<00:03, 61535189.70B/s]
 13%|█▎        | 26494976/210849368 [00:00<00:04, 43006700.54B/s]
 16%|█▌        | 33543168/210849368 [00:00<00:03, 44683717.01B/s]
 20%|█▉        | 41930752/210849368 [00:00<00:03, 50218718.12B/s]
 24%|██▎       | 50003968/210849368 [00:01<00:02, 57281064.19B/s]
 27%|██▋       | 57778176/210849368 [00:01<00:02, 62143893.88B/s]
 32%|███▏      | 66611200/210849368 [00:01<00:02, 69201153.14B/s]
 35%|███▌      | 73878528/210849368 [00:01<00:02, 64573677.85B/s]
 38%|███▊      | 80617472/210849368 [00:01<00:02, 64697092.04B/s]
 42%|████▏     | 88460288/210849368 [00:01<00:01, 68468364.77B/s]
 45%|████▌     | 95483904/210849368 [00:01<00:01, 65609227.00B/s]
 48%|████▊     | 102181888/210849368 [00:01<00:01, 58737646.87B/s]
 52%|█████▏    | 109043712/210849368 [00:01<00:01, 55798001.67B/s]
 55%|█████▍    | 115686400/210849368 [00:02<00:01, 55393212.98B/s]
 58%|█████▊    | 121339904/210849368 [00:02<00:01, 47729680.16B/s]
 60%|█████▉    | 126321664/210849368 [00:02<00:02, 37717136.60B/s]
 64%|██████▎   | 134028288/210849368 [00:02<00:01, 42874226.83B/s]
 66%|██████▌   | 138670080/210849368 [00:02<00:01, 39443266.03B/s]
 70%|██████▉   | 146577408/210849368 [00:02<00:01, 48071176.81B/s]
 74%|███████▎  | 155008000/210849368 [00:02<00:00, 56378881.93B/s]
 77%|███████▋  | 161412096/210849368 [00:03<00:00, 58318751.14B/s]
 80%|███████▉  | 167759872/210849368 [00:03<00:00, 47440376.18B/s]
 83%|████████▎ | 175800320/210849368 [00:03<00:00, 54716297.23B/s]
 87%|████████▋ | 184038400/210849368 [00:03<00:00, 61094784.59B/s]
 91%|█████████ | 192297984/210849368 [00:03<00:00, 66216387.30B/s]
 95%|█████████▍| 199366656/210849368 [00:03<00:00, 64603584.61B/s]
 98%|█████████▊| 206140416/210849368 [00:03<00:00, 61449459.03B/s]
100%|██████████| 210849368/210849368 [00:03<00:00, 54245018.05B/s]
25.5s	31	
  0%|          | 0/630 [00:00<?, ?B/s]
100%|██████████| 630/630 [00:00<00:00, 3116051.32B/s]
26.2s	32	/usr/local/lib/python3.10/dist-packages/pytorch_pretrained_biggan/model.py:279: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
26.2s	33	  state_dict = torch.load(resolved_model_file, map_location='cpu' if not torch.cuda.is_available() else None)
27.0s	34	Unseen classes: ['horse', 'moose', 'gorilla', 'fox', 'sheep', 'chimpanzee', 'squirrel', 'rhinoceros', 'rabbit', 'collie']
27.2s	35	/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
27.2s	36	  warnings.warn(_create_warning_msg(
27.2s	37	Generating images for class: horse
28.6s	38	Generated 50 images for horse
29.0s	39	Generated 100 images for horse
29.3s	40	Generated 150 images for horse
29.7s	41	Generated 200 images for horse
30.0s	42	Generated 250 images for horse
30.0s	43	Generating images for class: moose
30.0s	44	Error generating image for moose: 
30.0s	45	Generating images for class: gorilla
30.6s	46	Generated 300 images for gorilla
31.0s	47	Generated 350 images for gorilla
31.3s	48	Generated 400 images for gorilla
31.7s	49	Generated 450 images for gorilla
32.0s	50	Generated 500 images for gorilla
32.0s	51	Generating images for class: fox
32.6s	52	Generated 550 images for fox
32.9s	53	Generated 600 images for fox
33.3s	54	Generated 650 images for fox
33.6s	55	Generated 700 images for fox
34.0s	56	Generated 750 images for fox
34.0s	57	Generating images for class: sheep
34.6s	58	Generated 800 images for sheep
34.9s	59	Generated 850 images for sheep
35.3s	60	Generated 900 images for sheep
35.7s	61	Generated 950 images for sheep
36.0s	62	Generated 1000 images for sheep
36.0s	63	Generating images for class: chimpanzee
36.6s	64	Generated 1050 images for chimpanzee
36.9s	65	Generated 1100 images for chimpanzee
37.3s	66	Generated 1150 images for chimpanzee
37.6s	67	Generated 1200 images for chimpanzee
38.0s	68	Generated 1250 images for chimpanzee
38.0s	69	Generating images for class: squirrel
38.0s	70	Error generating image for squirrel: 
38.0s	71	Generating images for class: rhinoceros
38.0s	72	Error generating image for rhinoceros: 
38.0s	73	Generating images for class: rabbit
38.5s	74	Generated 1300 images for rabbit
38.9s	75	Generated 1350 images for rabbit
39.2s	76	Generated 1400 images for rabbit
39.6s	77	Generated 1450 images for rabbit
39.9s	78	Generated 1500 images for rabbit
39.9s	79	Generating images for class: collie
40.4s	80	Generated 1550 images for collie
40.8s	81	Generated 1600 images for collie
41.2s	82	Generated 1650 images for collie
41.5s	83	Generated 1700 images for collie
41.9s	84	Generated 1750 images for collie
41.9s	85	Original dataset size: 9544
41.9s	86	Generated dataset size: 1750
41.9s	87	Total dataset size after augmentation: 11294
77.4s	88	Epoch [1/13], Batch [100/239], Train Loss: 1.4339, Train Acc: 43.16%
108.6s	89	Epoch [1/13], Batch [200/239], Train Loss: 1.1913, Train Acc: 54.39%
137.9s	90	Epoch [1/13] Complete, Train Loss: 1.5572, Train Acc: 56.87%, Val Loss: 1.0040, Val Acc: 69.83%
173.1s	91	Epoch [2/13], Batch [100/239], Train Loss: 0.8353, Train Acc: 77.53%
205.1s	92	Epoch [2/13], Batch [200/239], Train Loss: 0.9399, Train Acc: 77.52%
234.0s	93	Epoch [2/13] Complete, Train Loss: 0.7238, Train Acc: 77.87%, Val Loss: 0.8229, Val Acc: 73.97%
269.3s	94	Epoch [3/13], Batch [100/239], Train Loss: 0.8284, Train Acc: 80.84%
301.4s	95	Epoch [3/13], Batch [200/239], Train Loss: 0.5899, Train Acc: 81.86%
330.2s	96	Epoch [3/13] Complete, Train Loss: 0.5650, Train Acc: 81.93%, Val Loss: 0.7817, Val Acc: 75.33%
365.5s	97	Epoch [4/13], Batch [100/239], Train Loss: 0.4010, Train Acc: 85.12%
397.6s	98	Epoch [4/13], Batch [200/239], Train Loss: 0.3320, Train Acc: 85.47%
426.4s	99	Epoch [4/13] Complete, Train Loss: 0.4481, Train Acc: 85.49%, Val Loss: 0.6527, Val Acc: 79.36%
462.0s	100	Epoch [5/13], Batch [100/239], Train Loss: 0.3996, Train Acc: 88.88%
494.0s	101	Epoch [5/13], Batch [200/239], Train Loss: 0.1908, Train Acc: 88.69%
522.9s	102	Epoch [5/13] Complete, Train Loss: 0.3394, Train Acc: 88.57%, Val Loss: 0.6159, Val Acc: 80.88%
558.2s	103	Epoch [6/13], Batch [100/239], Train Loss: 0.2110, Train Acc: 91.22%
590.2s	104	Epoch [6/13], Batch [200/239], Train Loss: 0.2391, Train Acc: 91.58%
619.1s	105	Epoch [6/13] Complete, Train Loss: 0.2535, Train Acc: 91.79%, Val Loss: 0.5417, Val Acc: 83.34%
654.5s	106	Epoch [7/13], Batch [100/239], Train Loss: 0.3477, Train Acc: 93.50%
686.4s	107	Epoch [7/13], Batch [200/239], Train Loss: 0.2228, Train Acc: 93.55%
715.1s	108	Epoch [7/13] Complete, Train Loss: 0.1925, Train Acc: 93.62%, Val Loss: 0.4711, Val Acc: 85.59%
750.5s	109	Epoch [8/13], Batch [100/239], Train Loss: 0.0913, Train Acc: 94.81%
782.5s	110	Epoch [8/13], Batch [200/239], Train Loss: 0.0575, Train Acc: 95.62%
811.0s	111	Epoch [8/13] Complete, Train Loss: 0.1400, Train Acc: 95.70%, Val Loss: 0.4659, Val Acc: 86.54%
846.5s	112	Epoch [9/13], Batch [100/239], Train Loss: 0.1721, Train Acc: 96.03%
878.4s	113	Epoch [9/13], Batch [200/239], Train Loss: 0.1158, Train Acc: 96.34%
906.9s	114	Epoch [9/13] Complete, Train Loss: 0.1115, Train Acc: 96.48%, Val Loss: 0.4661, Val Acc: 85.70%
942.6s	115	Epoch [10/13], Batch [100/239], Train Loss: 0.1555, Train Acc: 97.03%
974.6s	116	Epoch [10/13], Batch [200/239], Train Loss: 0.2615, Train Acc: 96.97%
1002.7s	117	Epoch [10/13] Complete, Train Loss: 0.0989, Train Acc: 96.92%, Val Loss: 0.4565, Val Acc: 87.27%
1038.6s	118	Epoch [11/13], Batch [100/239], Train Loss: 0.0995, Train Acc: 96.94%
1070.5s	119	Epoch [11/13], Batch [200/239], Train Loss: 0.0336, Train Acc: 97.09%
1098.7s	120	Epoch [11/13] Complete, Train Loss: 0.0938, Train Acc: 97.04%, Val Loss: 0.4775, Val Acc: 86.28%
1134.4s	121	Epoch [12/13], Batch [100/239], Train Loss: 0.0272, Train Acc: 97.34%
1166.4s	122	Epoch [12/13], Batch [200/239], Train Loss: 0.0095, Train Acc: 97.28%
1194.8s	123	Epoch [12/13] Complete, Train Loss: 0.0927, Train Acc: 97.26%, Val Loss: 0.4591, Val Acc: 86.69%
1230.4s	124	Epoch [13/13], Batch [100/239], Train Loss: 0.0778, Train Acc: 96.88%
1262.5s	125	Epoch [13/13], Batch [200/239], Train Loss: 0.1348, Train Acc: 96.70%
1290.9s	126	Epoch [13/13] Complete, Train Loss: 0.0950, Train Acc: 96.79%, Val Loss: 0.4811, Val Acc: 86.07%
1290.9s	127	Training complete.
1385.4s	128	/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py:2915: FutureWarning: --Exporter.preprocessors=["remove_papermill_header.RemovePapermillHeader"] for containers is deprecated in traitlets 5.0. You can pass `--Exporter.preprocessors item` ... multiple times to add items to a list.
1385.4s	129	  warn(
1385.4s	130	[NbConvertApp] Converting notebook __notebook__.ipynb to notebook
1385.8s	131	[NbConvertApp] Writing 2565151 bytes to __notebook__.ipynb
1387.0s	132	/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py:2915: FutureWarning: --Exporter.preprocessors=["nbconvert.preprocessors.ExtractOutputPreprocessor"] for containers is deprecated in traitlets 5.0. You can pass `--Exporter.preprocessors item` ... multiple times to add items to a list.
1387.0s	133	  warn(
1387.0s	134	[NbConvertApp] Converting notebook __notebook__.ipynb to html
1387.7s	135	[NbConvertApp] Support files will be in __results___files/
1387.7s	136	[NbConvertApp] Making directory __results___files
1387.7s	137	[NbConvertApp] Making directory __results___files
1387.7s	138	[NbConvertApp] Making directory __results___files
1387.7s	139	[NbConvertApp] Making directory __results___files
1387.7s	140	[NbConvertApp] Making directory __results___files
1387.7s	141	[NbConvertApp] Making directory __results___files
1387.7s	142	[NbConvertApp] Making directory __results___files
1387.7s	143	[NbConvertApp] Writing 356188 bytes to __results__.html