Time
#
Log Message
15.0s	1	Collecting pytorch-pretrained-biggan
15.1s	2	  Downloading pytorch_pretrained_biggan-0.1.1-py3-none-any.whl.metadata (11 kB)
15.1s	3	Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-biggan) (2.4.1+cu121)
15.1s	4	Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-biggan) (1.26.4)
15.1s	5	Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-biggan) (1.35.83)
15.1s	6	Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-biggan) (2.32.3)
15.1s	7	Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-biggan) (4.66.5)
15.1s	8	Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (3.16.1)
15.1s	9	Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (4.12.2)
15.1s	10	Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (1.13.3)
15.1s	11	Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (3.3)
15.1s	12	Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (3.1.4)
15.1s	13	Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (2024.6.1)
15.1s	14	Requirement already satisfied: botocore<1.36.0,>=1.35.83 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-biggan) (1.35.83)
15.1s	15	Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-biggan) (1.0.1)
15.1s	16	Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-biggan) (0.10.4)
15.1s	17	Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-biggan) (3.3.2)
15.1s	18	Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-biggan) (3.10)
15.1s	19	Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-biggan) (2.2.3)
15.1s	20	Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-biggan) (2024.8.30)
15.1s	21	Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.83->boto3->pytorch-pretrained-biggan) (2.8.2)
15.2s	22	Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-biggan) (2.1.5)
15.2s	23	Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch-pretrained-biggan) (1.3.0)
15.2s	24	Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.83->boto3->pytorch-pretrained-biggan) (1.16.0)
15.2s	25	Downloading pytorch_pretrained_biggan-0.1.1-py3-none-any.whl (27 kB)
18.1s	26	Installing collected packages: pytorch-pretrained-biggan
18.2s	27	Successfully installed pytorch-pretrained-biggan-0.1.1
19.4s	28	Collecting ranger-adabelief
19.5s	29	  Downloading ranger_adabelief-0.1.0-py3-none-any.whl.metadata (549 bytes)
19.5s	30	Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from ranger-adabelief) (2.4.1+cu121)
19.5s	31	Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->ranger-adabelief) (3.16.1)
19.5s	32	Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->ranger-adabelief) (4.12.2)
19.5s	33	Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->ranger-adabelief) (1.13.3)
19.5s	34	Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->ranger-adabelief) (3.3)
19.5s	35	Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->ranger-adabelief) (3.1.4)
19.5s	36	Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->ranger-adabelief) (2024.6.1)
19.5s	37	Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.0->ranger-adabelief) (2.1.5)
19.5s	38	Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.0->ranger-adabelief) (1.3.0)
19.6s	39	Downloading ranger_adabelief-0.1.0-py3-none-any.whl (5.6 kB)
21.8s	40	Installing collected packages: ranger-adabelief
22.0s	41	Successfully installed ranger-adabelief-0.1.0
26.2s	42	WordNet loaded successfully. Example synsets: [Synset('example.n.01'), Synset('model.n.07'), Synset('exemplar.n.01'), Synset('example.n.04'), Synset('case.n.01'), Synset('exercise.n.04')]
26.2s	43	[Synset('horse.n.01'), Synset('horse.n.02'), Synset('cavalry.n.01'), Synset('sawhorse.n.01'), Synset('knight.n.02'), Synset('horse.v.01')]
29.8s	44	
  0%|          | 0/210849368 [00:00<?, ?B/s]
  0%|          | 342016/210849368 [00:00<01:02, 3387958.15B/s]
  2%|▏         | 4383744/210849368 [00:00<00:08, 25083993.43B/s]
  6%|▋         | 13701120/210849368 [00:00<00:03, 56107971.53B/s]
 11%|█         | 23075840/210849368 [00:00<00:02, 70948086.98B/s]
 15%|█▌        | 32613376/210849368 [00:00<00:02, 79745642.74B/s]
 19%|█▉        | 40594432/210849368 [00:00<00:02, 75168468.82B/s]
 23%|██▎       | 48161792/210849368 [00:00<00:02, 69321331.37B/s]
 26%|██▋       | 55462912/210849368 [00:00<00:02, 70398286.56B/s]
 30%|███       | 63647744/210849368 [00:00<00:01, 73768704.93B/s]
 34%|███▍      | 71357440/210849368 [00:01<00:01, 74750756.74B/s]
 38%|███▊      | 79961088/210849368 [00:01<00:01, 78104915.32B/s]
 42%|████▏     | 88111104/210849368 [00:01<00:01, 79113873.61B/s]
 46%|████▌     | 96058368/210849368 [00:01<00:01, 75284335.88B/s]
 49%|████▉     | 103929856/210849368 [00:01<00:01, 76272218.17B/s]
 53%|█████▎    | 111603712/210849368 [00:01<00:01, 73836983.51B/s]
 56%|█████▋    | 119031808/210849368 [00:01<00:01, 72183087.59B/s]
 60%|██████    | 127028224/210849368 [00:01<00:01, 74405953.57B/s]
 64%|██████▍   | 134638592/210849368 [00:01<00:01, 74897668.29B/s]
 67%|██████▋   | 142154752/210849368 [00:01<00:00, 72304558.33B/s]
 71%|███████   | 149440512/210849368 [00:02<00:00, 72463092.13B/s]
 75%|███████▌  | 158738432/210849368 [00:02<00:00, 78434032.42B/s]
 80%|███████▉  | 168118272/210849368 [00:02<00:00, 82945346.67B/s]
 84%|████████▍ | 177133568/210849368 [00:02<00:00, 85070348.19B/s]
 88%|████████▊ | 185668608/210849368 [00:02<00:00, 78125696.42B/s]
 92%|█████████▏| 194504704/210849368 [00:02<00:00, 80992486.70B/s]
 96%|█████████▌| 202713088/210849368 [00:02<00:00, 78154515.57B/s]
100%|█████████▉| 210617344/210849368 [00:02<00:00, 66814465.77B/s]
100%|██████████| 210849368/210849368 [00:02<00:00, 72495884.46B/s]
30.4s	45	
  0%|          | 0/630 [00:00<?, ?B/s]
100%|██████████| 630/630 [00:00<00:00, 2297749.15B/s]
31.0s	46	/usr/local/lib/python3.10/dist-packages/pytorch_pretrained_biggan/model.py:279: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
31.0s	47	  state_dict = torch.load(resolved_model_file, map_location='cpu' if not torch.cuda.is_available() else None)
32.1s	48	Generating images...
35.0s	49	Class antelope: 250 images added.
35.0s	50	No synset found for grizzly+bear. Skipping.
35.0s	51	Class grizzly+bear: 0 images added.
35.0s	52	No synset found for killer+whale. Skipping.
35.0s	53	Class killer+whale: 0 images added.
36.8s	54	Class beaver: 250 images added.
38.6s	55	Class dalmatian: 250 images added.
38.6s	56	No synset found for persian+cat. Skipping.
38.6s	57	Class persian+cat: 0 images added.
42.3s	58	Class horse: 500 images added.
42.3s	59	No synset found for german+shepherd. Skipping.
42.3s	60	Class german+shepherd: 0 images added.
42.3s	61	No synset found for blue+whale. Skipping.
42.3s	62	Class blue+whale: 0 images added.
42.3s	63	No synset found for siamese+cat. Skipping.
42.3s	64	Class siamese+cat: 0 images added.
42.3s	65	Error generating images for skunk: 
42.3s	66	Class skunk: 0 images added.
42.3s	67	Error generating images for mole: 
42.3s	68	Class mole: 0 images added.
44.1s	69	Class tiger: 250 images added.
46.0s	70	Class hippopotamus: 250 images added.
47.8s	71	Class leopard: 250 images added.
47.8s	72	Error generating images for moose: 
47.8s	73	Class moose: 0 images added.
47.8s	74	No synset found for spider+monkey. Skipping.
47.8s	75	Class spider+monkey: 0 images added.
47.8s	76	No synset found for humpback+whale. Skipping.
47.8s	77	Class humpback+whale: 0 images added.
49.6s	78	Class elephant: 250 images added.
53.3s	79	Class gorilla: 500 images added.
55.1s	80	Class ox: 250 images added.
58.8s	81	Class fox: 500 images added.
62.5s	82	Class sheep: 500 images added.
62.5s	83	Error generating images for seal: 
62.5s	84	Class seal: 0 images added.
66.3s	85	Class chimpanzee: 500 images added.
68.1s	86	Class hamster: 250 images added.
68.1s	87	Error generating images for squirrel: 
68.1s	88	Class squirrel: 0 images added.
68.1s	89	Error generating images for rhinoceros: 
68.1s	90	Class rhinoceros: 0 images added.
71.8s	91	Class rabbit: 500 images added.
73.7s	92	Class bat: 250 images added.
73.7s	93	Error generating images for giraffe: 
73.7s	94	Class giraffe: 0 images added.
75.6s	95	Class wolf: 250 images added.
77.4s	96	Class chihuahua: 250 images added.
77.4s	97	Error generating images for rat: 
77.4s	98	Class rat: 0 images added.
79.3s	99	Class weasel: 250 images added.
81.2s	100	Class otter: 250 images added.
83.0s	101	Class buffalo: 250 images added.
84.9s	102	Class zebra: 250 images added.
84.9s	103	No synset found for giant+panda. Skipping.
84.9s	104	Class giant+panda: 0 images added.
84.9s	105	Error generating images for deer: 
84.9s	106	Class deer: 0 images added.
86.8s	107	Class bobcat: 250 images added.
88.7s	108	Class pig: 250 images added.
90.6s	109	Class lion: 250 images added.
92.5s	110	Class mouse: 250 images added.
92.5s	111	No synset found for polar+bear. Skipping.
92.5s	112	Class polar+bear: 0 images added.
96.2s	113	Class collie: 500 images added.
96.2s	114	Error generating images for walrus: 
96.2s	115	Class walrus: 0 images added.
96.2s	116	Error generating images for raccoon: 
96.2s	117	Class raccoon: 0 images added.
96.2s	118	Error generating images for cow: 
96.2s	119	Class cow: 0 images added.
96.2s	120	Error generating images for dolphin: 
96.2s	121	Class dolphin: 0 images added.
96.2s	122	Total new images added: 8500
96.2s	123	Final dataset size: 18044
96.2s	124	Training set size: 14435
96.2s	125	Validation set size: 3609
96.3s	126	/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
96.3s	127	  warnings.warn(_create_warning_msg(
100.4s	128	/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
100.4s	129	  warnings.warn(_create_warning_msg(
147.7s	130	Epoch [1/5], Batch [100/452], Train Loss: 0.5644, Train Acc: 62.22%
194.2s	131	Epoch [1/5], Batch [200/452], Train Loss: 0.4057, Train Acc: 73.41%
239.7s	132	Epoch [1/5], Batch [300/452], Train Loss: 0.4757, Train Acc: 77.85%
285.8s	133	Epoch [1/5], Batch [400/452], Train Loss: 0.4891, Train Acc: 80.16%
334.9s	134	Epoch [1/5] Complete, Train Loss: 0.6971, Train Acc: 80.97%, Val Loss: 0.3030, Val Acc: 90.39%
383.8s	135	Epoch [2/5], Batch [100/452], Train Loss: 0.5580, Train Acc: 91.91%
429.8s	136	Epoch [2/5], Batch [200/452], Train Loss: 0.1942, Train Acc: 91.67%
476.0s	137	Epoch [2/5], Batch [300/452], Train Loss: 0.3113, Train Acc: 91.77%
522.0s	138	Epoch [2/5], Batch [400/452], Train Loss: 0.2390, Train Acc: 91.74%
570.1s	139	Epoch [2/5] Complete, Train Loss: 0.2545, Train Acc: 91.68%, Val Loss: 0.3317, Val Acc: 89.53%
619.1s	140	Epoch [3/5], Batch [100/452], Train Loss: 0.1658, Train Acc: 94.88%
664.9s	141	Epoch [3/5], Batch [200/452], Train Loss: 0.1219, Train Acc: 95.12%
711.0s	142	Epoch [3/5], Batch [300/452], Train Loss: 0.2835, Train Acc: 95.23%
757.1s	143	Epoch [3/5], Batch [400/452], Train Loss: 0.0292, Train Acc: 95.33%
804.9s	144	Epoch [3/5] Complete, Train Loss: 0.1464, Train Acc: 95.27%, Val Loss: 0.2683, Val Acc: 92.05%
853.7s	145	Epoch [4/5], Batch [100/452], Train Loss: 0.1477, Train Acc: 97.25%
899.5s	146	Epoch [4/5], Batch [200/452], Train Loss: 0.0177, Train Acc: 97.53%
945.7s	147	Epoch [4/5], Batch [300/452], Train Loss: 0.0777, Train Acc: 97.56%
991.7s	148	Epoch [4/5], Batch [400/452], Train Loss: 0.0180, Train Acc: 97.66%
1039.7s	149	Epoch [4/5] Complete, Train Loss: 0.0717, Train Acc: 97.66%, Val Loss: 0.2416, Val Acc: 92.68%
1088.7s	150	Epoch [5/5], Batch [100/452], Train Loss: 0.0633, Train Acc: 98.69%
1134.7s	151	Epoch [5/5], Batch [200/452], Train Loss: 0.0034, Train Acc: 98.59%
1180.9s	152	Epoch [5/5], Batch [300/452], Train Loss: 0.0020, Train Acc: 98.59%
1226.8s	153	Epoch [5/5], Batch [400/452], Train Loss: 0.0663, Train Acc: 98.70%
1274.9s	154	Epoch [5/5] Complete, Train Loss: 0.0407, Train Acc: 98.70%, Val Loss: 0.2367, Val Acc: 93.85%
1274.9s	155	Training complete.
1409.1s	156	/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py:2915: FutureWarning: --Exporter.preprocessors=["remove_papermill_header.RemovePapermillHeader"] for containers is deprecated in traitlets 5.0. You can pass `--Exporter.preprocessors item` ... multiple times to add items to a list.
1409.1s	157	  warn(
1409.1s	158	[NbConvertApp] Converting notebook __notebook__.ipynb to notebook
1409.5s	159	[NbConvertApp] Writing 44352 bytes to __notebook__.ipynb
1410.9s	160	/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py:2915: FutureWarning: --Exporter.preprocessors=["nbconvert.preprocessors.ExtractOutputPreprocessor"] for containers is deprecated in traitlets 5.0. You can pass `--Exporter.preprocessors item` ... multiple times to add items to a list.
1410.9s	161	  warn(
1410.9s	162	[NbConvertApp] Converting notebook __notebook__.ipynb to html
1411.7s	163	[NbConvertApp] Writing 349245 bytes to __results__.html
'submission.csv' will be evaluated for your final score