{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":90860,"databundleVersionId":10740331,"sourceType":"competition"},{"sourceId":10446141,"sourceType":"datasetVersion","datasetId":6466119}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import models\nfrom PIL import Image","metadata":{"id":"vdMi4cTEsHSM","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T12:27:10.355804Z","iopub.execute_input":"2025-01-12T12:27:10.356253Z","iopub.status.idle":"2025-01-12T12:27:10.361976Z","shell.execute_reply.started":"2025-01-12T12:27:10.356225Z","shell.execute_reply":"2025-01-12T12:27:10.361039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install pytorch-pretrained-biggan\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T12:27:14.67608Z","iopub.execute_input":"2025-01-12T12:27:14.676519Z","iopub.status.idle":"2025-01-12T12:27:19.169088Z","shell.execute_reply.started":"2025-01-12T12:27:14.676483Z","shell.execute_reply":"2025-01-12T12:27:19.16815Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport nltk\n\n# Define the expected NLTK directory structure\nnltk_data_path = '/kaggle/working/nltk_data/corpora/'\nos.makedirs(nltk_data_path, exist_ok=True)\n\n# Path to the uploaded wordnet directory\nwordnet_source_path = '/kaggle/input/wordnetn/wordnet/'\nwordnet_dest_path = os.path.join(nltk_data_path, 'wordnet')\n\n# Move or copy the wordnet folder to the expected location\nif not os.path.exists(wordnet_dest_path):\n    shutil.copytree(wordnet_source_path, wordnet_dest_path)\n\n# Add the working directory to NLTK's data path\nnltk.data.path.append('/kaggle/working/nltk_data/')\n# Test WordNet\nfrom nltk.corpus import wordnet\n\ntry:\n    syns = wordnet.synsets('example')\n    print(f\"WordNet loaded successfully. Example synsets: {syns}\")\nexcept Exception as e:\n    print(f\"Error loading WordNet: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T12:27:24.641205Z","iopub.execute_input":"2025-01-12T12:27:24.641518Z","iopub.status.idle":"2025-01-12T12:27:27.482753Z","shell.execute_reply.started":"2025-01-12T12:27:24.641494Z","shell.execute_reply":"2025-01-12T12:27:27.481892Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import nltk\n\nnltk.data.path.append('/kaggle/working/nltk_data')\nfrom nltk.corpus import wordnet\n\nprint(wordnet.synsets('horse'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T12:27:33.18077Z","iopub.execute_input":"2025-01-12T12:27:33.18123Z","iopub.status.idle":"2025-01-12T12:27:33.186668Z","shell.execute_reply.started":"2025-01-12T12:27:33.181205Z","shell.execute_reply":"2025-01-12T12:27:33.186006Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset\nfrom torch.utils.data import DataLoader\nimport os\nfrom PIL import Image\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchvision import transforms, models\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample)\nimport random\nimport nltk\nimport timm\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n\nbiggan = BigGAN.from_pretrained('biggan-deep-128').to('cuda')\n\nclasses_file = \"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/classes.txt\"\npredicate_matrix_file = \"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/predicate-matrix-continuous.txt\"\ntrain_dir = \"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/train\"\ndef load_classes(file_path):\n    with open(file_path, \"r\") as f:\n        classes = [line.strip().split('\\t')[-1] for line in f.readlines()]\n    return classes\n\ndef load_and_normalize_predicate_matrix(file_path):\n    predicate_matrix = np.loadtxt(file_path)\n    predicate_matrix = (predicate_matrix - predicate_matrix.min(axis=0)) / (predicate_matrix.max(axis=0) - predicate_matrix.min(axis=0) + 1e-8)\n    return predicate_matrix\n\nclasses = load_classes(classes_file)\npredicate_matrix = load_and_normalize_predicate_matrix(predicate_matrix_file)\n\nfolder_classes = set(os.listdir(train_dir))\nunseen_classes = [cls for cls in classes if cls not in folder_classes]\nprint(f\"Unseen classes: {unseen_classes}\")\n\nclass ImageDataset(Dataset):\n    def __init__(self, root_dir, class_to_idx, transform=None):\n        self.root_dir = root_dir\n        self.class_to_idx = class_to_idx\n        self.transform = transform\n        self.data = []\n        for class_name in os.listdir(root_dir):\n            class_path = os.path.join(root_dir, class_name)\n            if os.path.isdir(class_path):\n                class_idx = class_to_idx[class_name]\n                for img_name in os.listdir(class_path):\n                    img_path = os.path.join(class_path, img_name)\n                    self.data.append((img_path, class_idx))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path, label = self.data[idx]\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),  # Randomly flip the image vertically\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n    transforms.RandomRotation(30),  # Increased rotation angle\n    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random affine transformations\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\nclass_to_idx = {cls: idx for idx, cls in enumerate(classes)}\ndataset = ImageDataset(train_dir, class_to_idx, transform)\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=8)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=8)\n\nunseen_class_to_idx = {cls: idx + len(folder_classes) for idx, cls in enumerate(unseen_classes)}\n# Manual synset mapping for problematic classes\nmanual_synsets = {\n    \"moose\": \"elk.n.01\",\n    \"rhinoceros\": \"rhinoceros.n.01\",\n    \"squirrel\": \"squirrel.n.01\"\n}\n\ngenerated_data = []\nfor class_name in unseen_classes:\n    try:\n        print(f\"Generating images for class: {class_name}\")\n        synsets = wordnet.synsets(class_name.replace(\"+\", \" \"))\n        # Use manual mapping if the synset is not directly available\n        synset_name = manual_synsets.get(class_name) if class_name in manual_synsets else synsets[0].name()\n        if not synset_name:\n            print(f\"No valid synset found for {class_name}, skipping.\")\n            continue\n\n        class_idx = unseen_class_to_idx[class_name]\n        first_image_logged = False\n        for batch_start in range(0, 250, 50):\n            batch_size = min(50, 250 - batch_start)\n            class_vector = torch.tensor(\n                one_hot_from_names([synset_name.split('.')[0]], batch_size=batch_size),\n                dtype=torch.float32\n            ).to('cuda')\n            noise_vector = torch.tensor(\n                truncated_noise_sample(truncation=0.4, batch_size=batch_size, seed=42),\n                dtype=torch.float32\n            ).to('cuda')\n\n            with torch.no_grad():\n                output = biggan(noise_vector, class_vector, truncation=0.4)\n            for i in range(output.shape[0]):\n                image = transforms.ToPILImage()(output[i].cpu().squeeze())\n                generated_data.append((image, class_idx))\n                if not first_image_logged:\n                    plt.imshow(image)\n                    plt.title(f\"Generated Image for {class_name}\")\n                    plt.axis('off')\n                    plt.show()\n                    first_image_logged = True\n            print(f\"Generated {len(generated_data)} images for {class_name}\")\n    except Exception as e:\n        print(f\"Error generating image for {class_name}: {e}\")\n\n\n\n\n# Add generated data to the dataset\n\nfor img, label in generated_data:\n    dataset.data.append((img, label))\n\nprint(f\"Original dataset size: {len(train_dataset) + len(val_dataset)}\")\nprint(f\"Generated dataset size: {len(generated_data)}\")\nprint(f\"Total dataset size after augmentation: {len(dataset)}\")\n# Model initialization using Swin Transformer\nmodel = timm.create_model('efficientnet_b4', pretrained=True, num_classes=50)\nmodel = model.to(device)\n\nfor param in model.parameters():\n    param.requires_grad = True\n\n\n# Define loss, optimizer, and scheduler\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-3) \nscheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.005, total_steps=9 * len(train_loader))\n\n\n# Training and validation loop\nnum_epochs = 9\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    for batch_idx, (images, labels) in enumerate(train_loader):\n        images, labels = images.to(device), labels.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Metrics calculation\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        correct_train += (predicted == labels).sum().item()\n        total_train += labels.size(0)\n\n        if (batch_idx + 1) % 100 == 0:\n            print(f\"Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_idx + 1}/{len(train_loader)}], Train Loss: {loss.item():.4f}, Train Acc: {100 * correct_train / total_train:.2f}%\")\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = 100 * correct_train / total_train\n\n    # Validation phase\n    model.eval()\n    val_loss = 0.0\n    correct_val = 0\n    total_val = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            # Metrics calculation\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            correct_val += (predicted == labels).sum().item()\n            total_val += labels.size(0)\n\n    val_loss /= len(val_loader)\n    val_acc = 100 * correct_val / total_val\n\n    # Scheduler step\n    scheduler.step()\n\n    print(f\"Epoch [{epoch + 1}/{num_epochs}] Complete, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n\nprint(\"Training complete.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T12:30:54.995366Z","iopub.execute_input":"2025-01-12T12:30:54.995698Z","iopub.status.idle":"2025-01-12T12:56:32.557124Z","shell.execute_reply.started":"2025-01-12T12:30:54.995659Z","shell.execute_reply":"2025-01-12T12:56:32.555392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nimport torch\n\n\n# Prediction\ntest_dir = \"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/test\"\nmodel.eval()\ntest_images = [f for f in os.listdir(test_dir) if f.endswith('.jpg')]\ntest_predictions = []\n\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\nfor img_name in test_images:\n    img_path = os.path.join(test_dir, img_name)\n    image = Image.open(img_path).convert('RGB')\n    image = transform(image).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        outputs = model(image)\n        predicted_class = torch.argmax(outputs, dim=1).item()\n        class_name = classes[predicted_class]  # Get the class name\n        test_predictions.append((img_name, class_name))\n\n# Save Predictions\nsubmission = pd.DataFrame(test_predictions, columns=['image_id', 'class'])\nsubmission.to_csv(\"/kaggle/working/submission.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}